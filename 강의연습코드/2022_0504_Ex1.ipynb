{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567e49c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.6.5', '0.6.0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk, kss, konlpy\n",
    "nltk.__version__,konlpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022943a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Korean Sentence Splitter]: Initializing Pynori...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['안녕 하세요']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = '안녕 하세요'\n",
    "kss.split_sentences(tt) # 버전이 따로 확인되지는 않음. 메소드 써지면 불러와진거."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bcb5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"Don't be fooled by the dark sounding name, Mr.Jone's Orphanage is as cheery as cheery goes for a pastry shop.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b70610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3aa6c",
   "metadata": {},
   "source": [
    "방법1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155b3c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'fooled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'sounding',\n",
       " 'name',\n",
       " ',',\n",
       " 'Mr.Jone',\n",
       " \"'s\",\n",
       " 'Orphanage',\n",
       " 'is',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'goes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pastry',\n",
       " 'shop',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed33dd5",
   "metadata": {},
   "source": [
    "방법2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a96f8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'be',\n",
       " 'fooled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'sounding',\n",
       " 'name',\n",
       " ',',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Jone',\n",
       " \"'\",\n",
       " 's',\n",
       " 'Orphanage',\n",
       " 'is',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'goes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pastry',\n",
       " 'shop',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordPunctTokenizer().tokenize(t) # 첫글자 대문자면 class, 인스턴스 만들어줘야한다.? 공부하기!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ab3d7",
   "metadata": {},
   "source": [
    "방법3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea8799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"don't\",\n",
       " 'be',\n",
       " 'fooled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'sounding',\n",
       " 'name',\n",
       " 'mr',\n",
       " \"jone's\",\n",
       " 'orphanage',\n",
       " 'is',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'goes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pastry',\n",
       " 'shop']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_word_sequence(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adcdbf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don't be fooled by the dark sounding name, hom-data Mr.Jone's Orphanage is as cheery as cheery goes for a pastry shop.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer # 표준\n",
    "t2 = \"Don't be fooled by the dark sounding name, hom-data Mr.Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149e6a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Do',\n",
       " \"n't\",\n",
       " 'be',\n",
       " 'fooled',\n",
       " 'by',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'sounding',\n",
       " 'name',\n",
       " ',',\n",
       " 'hom-data',\n",
       " 'Mr.Jone',\n",
       " \"'s\",\n",
       " 'Orphanage',\n",
       " 'is',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'as',\n",
       " 'cheery',\n",
       " 'goes',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pastry',\n",
       " 'shop',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreebankWordTokenizer().tokenize(t2)\n",
    "word_tokenize(t2) # 둘이 똑같은 결과나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061e509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a937e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['His barber kept his word.',\n",
       " 'But keeping such a huge secret to himself was driving him crazy.',\n",
       " 'Finally, the barber went up a mountain and almost to the edge of a cliff.',\n",
       " 'He dug a hole in the midst of some reeds.',\n",
       " 'He looked about, to make sure no one was near.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21e35e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, Ph.D. the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a121474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['His barber kept his word.',\n",
       " 'But keeping such a huge secret to himself was driving him crazy.',\n",
       " 'Finally, Ph.D. the barber went up a mountain and almost to the edge of a cliff.',\n",
       " 'He dug a hole in the midst of some reeds.',\n",
       " 'He looked about, to make sure no one was near.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aa8ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = \"이번 수업은 오늘 진행 됩니다. 그리고 내일 부터는 휴일 입니다. 다음주 월요일날 2차 수업이 진행 됩니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a3e331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ddb7c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이번 수업은 오늘 진행 됩니다.', '그리고 내일 부터는 휴일 입니다.', '다음주 월요일날 2차 수업이 진행 됩니다.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kss.split_sentences(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60977490",
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb48b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'actively',\n",
       " 'looking',\n",
       " 'for',\n",
       " 'Ph.D.',\n",
       " 'students',\n",
       " '.',\n",
       " 'and',\n",
       " 'you',\n",
       " 'are',\n",
       " 'a',\n",
       " 'Ph.D.',\n",
       " 'student',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "t_t = word_tokenize(t6)\n",
    "t_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d291ca78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('actively', 'RB'),\n",
       " ('looking', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('Ph.D.', 'NNP'),\n",
       " ('students', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('and', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('Ph.D.', 'NNP'),\n",
       " ('student', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(t_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4978074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 추출해서 품사로 태그 붙이겠다.\n",
    "from konlpy.tag import Okt \n",
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20207c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['우리',\n",
       " '는',\n",
       " '즐거운',\n",
       " '어린이날',\n",
       " '부터',\n",
       " '휴일',\n",
       " '입니다',\n",
       " '.',\n",
       " '고생',\n",
       " '한',\n",
       " '여러분',\n",
       " '휴일',\n",
       " '을',\n",
       " '즐기세요',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = Okt()\n",
    "#형태소\n",
    "t7 = \"우리는 즐거운 어린이날 부터 휴일 입니다. 고생한 여러분 휴일을 즐기세요.\"\n",
    "n1.morphs(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd301d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('우리', 'Noun'),\n",
       " ('는', 'Josa'),\n",
       " ('즐거운', 'Adjective'),\n",
       " ('어린이날', 'Noun'),\n",
       " ('부터', 'Noun'),\n",
       " ('휴일', 'Noun'),\n",
       " ('입니다', 'Adjective'),\n",
       " ('.', 'Punctuation'),\n",
       " ('고생', 'Noun'),\n",
       " ('한', 'Josa'),\n",
       " ('여러분', 'Noun'),\n",
       " ('휴일', 'Noun'),\n",
       " ('을', 'Josa'),\n",
       " ('즐기세요', 'Verb'),\n",
       " ('.', 'Punctuation')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#품사태깅\n",
    "n1.pos(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb0fa03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['우리', '어린이날', '부터', '휴일', '고생', '여러분', '휴일']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 명사추출\n",
    "n1.nouns(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc58af12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['우리',\n",
       "  '는',\n",
       "  '즐겁',\n",
       "  'ㄴ',\n",
       "  '어린이날',\n",
       "  '부터',\n",
       "  '휴일',\n",
       "  '이',\n",
       "  'ㅂ니다',\n",
       "  '.',\n",
       "  '고생',\n",
       "  '하',\n",
       "  'ㄴ',\n",
       "  '여러',\n",
       "  '분',\n",
       "  '휴일',\n",
       "  '을',\n",
       "  '즐기',\n",
       "  '세요',\n",
       "  '.'],\n",
       " [('우리', 'NP'),\n",
       "  ('는', 'JX'),\n",
       "  ('즐겁', 'VA'),\n",
       "  ('ㄴ', 'ETD'),\n",
       "  ('어린이날', 'NNG'),\n",
       "  ('부터', 'JX'),\n",
       "  ('휴일', 'NNG'),\n",
       "  ('이', 'VCP'),\n",
       "  ('ㅂ니다', 'EFN'),\n",
       "  ('.', 'SF'),\n",
       "  ('고생', 'NNG'),\n",
       "  ('하', 'XSV'),\n",
       "  ('ㄴ', 'ETD'),\n",
       "  ('여러', 'MDT'),\n",
       "  ('분', 'NNB'),\n",
       "  ('휴일', 'NNG'),\n",
       "  ('을', 'JKO'),\n",
       "  ('즐기', 'VV'),\n",
       "  ('세요', 'EFN'),\n",
       "  ('.', 'SF')],\n",
       " ['우리', '어린이날', '휴일', '고생', '분'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2 = Kkma()\n",
    "n2.morphs(t7),n2.pos(t7),n2.nouns(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a3574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t8 = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8f162c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 정규표현식 공부?\n",
    "# string에 대해서 접근하는거라 언어랑 상관없이 적용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3abec92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'우리는 즐거운 어린이날 입니다 여러분들이 고생했으니 휴일을 즐겁게 보냈으면.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ck = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "ck.sub('',t8)\n",
    "t7 = '우리는 즐거운 어린이날 입니다. 난 여러분들이 고생했으니 휴일을 좀 많이 즐겁게 보냈으면 해요.'\n",
    "ck.sub('',t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df1dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
